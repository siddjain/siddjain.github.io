---
layout: mathjax-post
title:  "Understanding how quantum annealing can be used to solve the QUBO problem"
date:   2021-08-05 00:00:00 -0700
categories: quantum-computing
description: understand the math behind how quantum annealing can be used to solve the QUBO problem
---
= Understanding how quantum annealing can be used to solve the QUBO problem
Siddharth Jain <siddjain@live.com>
:revdate: 2021-08-05 00:00:00 -0800
:doctype: article
:stem: latexmath
:eqnums: all
:xrefstyle: short

== Preface: defining the problem

Recently I had a chance to try out D-Wave's quantum computer. Reading their documentation, it seems this device can only do one thing which is to find the stem:[x]
that minimizes stem:[x^T Q x] where stem:[x] is a stem:[n] length vector of stem:[0]s and stem:[1]s and stem:[Q] is a symmetrical stem:[n \times n] matrix. This problem is
also known as Quadratic Unconstrained Binary Optimization or https://en.wikipedia.org/wiki/Quadratic_unconstrained_binary_optimization[QUBO]. Ok, no problem.

Then I read that this device uses (and works by doing) https://en.wikipedia.org/wiki/Quantum_annealing[quantum annealing] (QA). Now the problem:

_I can find no book or reference showing that how these two things are related. How will doing QA solve a QUBO?_

Wikipedia's page on QA says:

> The transverse field is finally switched off, and the system is expected to have reached the ground state of the classical Ising model that corresponds to the solution to the original optimization problem

_But how? where is the proof?_ QM tells us that the ground-state is given by the eigenvector corresponding to lowest eigenvalue of the Hamiltonian stem:[H]. 
How is finding the minimum of stem:[x^T Q x] (**P1**) equivalent to finding the (lowest eigenvalued) eigenvector of a matrix stem:[H] (**P2**)? And if so,
what is relation between stem:[Q] and stem:[H]? If **P1** and **P2** were same how come books on quadratic programming or https://en.wikipedia.org/wiki/Quadratic_programming[wikipedia]
make no note of it?

I actually asked this on https://quantumcomputing.stackexchange.com/questions/19654/how-is-eigendecomposition-of-a-hamiltonian-equivalent-to-finding-the-minimum-of[Stack Overflow]
to which the response (answer) was that consider stem:[Q = H] and a proof minimizing stem:[x^T H x] copied below under terms of CC BY-SA license:

'''
image::/assets/images/so_answer_to_qubo_question.png[]
'''

There are many problems with this answer:

* The stem:[x] in stem:[\langle x | H | x \rangle] is a unit-length vector but the stem:[x] in QUBO is not a unit-length
 vector. Its length can be stem:[0] or more than stem:[1].

* The stem:[x] in the answer is a vector of _continuous_ complex variables whereas the stem:[x] in QUBO contains only stem:[0]s and stem:[1]s.

* The stem:[x] in the answer is the wave function and so its length is actually stem:[2^n]! Similarly, shouldn't the Hamiltonian stem:[H] be a stem:[2^n \times 2^n] matrix whereas
stem:[Q] is stem:[n \times n]?

In other words, the answer is unfortunately completely incorrect (no offense to the person who answered it). When I tried to point out these things, Stack Overflow users (many of them 
with stem:[>10]k reputation I believe) ironically downvoted my question and even voted to close it. The question kept bothering me though.
The best I could grasp is that we use QA to minimize stem:[\langle \Psi | H | \Psi \rangle] for some stem:[H] - what stem:[H] is continued to be unclear - make an observation 
(measurement) and map the result to the stem:[x] of the original QUBO problem. But how does that minimize stem:[x^T Q x] is completely unclear and voodoo until finally I got it one 
morning as I was getting ready to go to work...

== How it works

The Ising Hamiltonian stem:[H] can be seen in books or papers as defined like this:

image::/assets/images/ising_hamiltonian.png[]

The term we need to concern ourselves with is the final Hamiltonian:

image::/assets/images/ising_final_hamiltonian.png[]

What the heck does stem:[\sigma_i^z] even mean? No book will tell you that. That is why we need to go to a school
where we can ask questions to a real professor. The only place where I could find an explanation was https://arxiv.org/abs/0804.4884[this]
paper (which I found as I was writing this article and after having worked it out myself) where he explains that:

image::/assets/images/ising_hamiltonian_explained.png[]

taking an example stem:[n=3], what the equation is saying is really this:

[latexmath]
++++
\begin{align}
\begin{split}
H & = h_1 Z \otimes I \otimes I \\
  & + h_2 I \otimes Z \otimes I \\
  & + h_3 I \otimes I \otimes Z \\
  & + J_{12} Z \otimes Z \otimes I \\
  & + J_{13} Z \otimes I \otimes Z \\
  & + J_{23} I \otimes Z \otimes Z \\
\end{split}
\end{align}
++++ 

where I use stem:[Z] for the stem:[2 \times 2] Pauli stem:[\sigma^z] matrix. We can see that stem:[H] is a stem:[2^3 \times 2^3] matrix.
What are the eigenvalues of stem:[H]? The eigenvalues of stem:[Z] are stem:[\{-1, +1\}] and stem:[I] has only one eigenvalue namely stem:[1].
We use following three properties which play a key role:

* **Property 1** The eigenvalues of tensor product of matrices are equal to product of constituent eigenvalues i.e. 

[latexmath]
++++
\begin{equation}
\textrm{eig}(A \otimes B) = \textrm{eig}(A) \times \textrm{eig}(B)
\end{equation}
++++

refer some book on Linear Algebra if you need. The other key fact is this

* **Property 2** If stem:[A] and stem:[B] are two matrices and stem:[C] is the sum of stem:[A] and stem:[B], then in general
the eigenvalues of stem:[C] are not equal to the sum of eigenvalues of stem:[A] and stem:[B], but if stem:[A] and stem:[B]
have the same eigenvectors, then the eigenvalues do add up! In that case:

[latexmath]
++++
\begin{equation}
\textrm{eig}(A + B) = \textrm{eig}(A) + \textrm{eig}(B) \textrm{if A and B have same eigenvectors}
\end{equation}
++++

* **Property 3** The eigenvectors of tensor product of matrices are equal to tensor product of constituent eigenvectors i.e.

[latexmath]
++++
\begin{equation}
\textrm{eigvec}(A \otimes B) = \textrm{eigvec}(A) \otimes \textrm{eigvec}(B)
\end{equation}
++++

this is related to Property 1 and same proof applies.

Now the eigenvectors of stem:[Z] are stem:[(1,0)^T] and stem:[(0,1)^T]. Any vector stem:[v] is an eigenvector of stem:[I]
but to choose a basis, we choose the same eigenvectors stem:[(1,0)^T] and stem:[(0,1)^T] for stem:[I] as well. 
With this we can show that the stem:[2^3] eigenvalues (allowed energy levels) of stem:[H] are in fact given by:

[latexmath]
++++
\begin{align}
\begin{split}
E & = h_1 s_1 + h_2 s_2 + h_3 s_3 + J_{12} s_1 s_2 + J_{13} s_1 s_3 + J_{23} s_2 s_3 
\end{split}
\end{align}
++++ 

where stem:[s_1, s_2, s_3] are binary variables taking on values stem:[\{-1, +1\}] (the eigenvalues of stem:[Z]).
E.g., the combination stem:[(-1,+1,-1)] of stem:[(s_1, s_2, s_3)] gives one possible value of stem:[E].
This is nothing but the QUBO cost function. The ground-state is the state that minimizes stem:[E]
and if we measure the values of the spins (qubits) in the ground state (measurement of a qubit will yield stem:[-1] or stem:[+1])
we will find the vector stem:[x] that minimizes the QUBO cost function. So this is how it works.
If you do the math, it turns out the (final) Ising Hamiltonian is actually a diagonal matrix containing the energy values stem:[E] on its diagonal.
All the off-diagonal elements are stem:[0].

This also explains why the D-Wave computer is a special purpose computer because its Hamiltonian is constrained to be an Ising Hamiltonian
in a transverse field.